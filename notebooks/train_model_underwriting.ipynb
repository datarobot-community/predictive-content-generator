{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import datarobot as dr\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# The notebook should be executed from the project root directory\n",
    "if \"_correct_path\" not in locals():\n",
    "    os.chdir(\"..\")\n",
    "    sys.path.append(\".\")\n",
    "    print(f\"changed dir to {Path('.').resolve()})\")\n",
    "    _correct_path = True\n",
    "load_dotenv()\n",
    "client = dr.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "from infra.settings_generative import custom_metric_baselines\n",
    "from infra.settings_main import project_name\n",
    "from nbo.credentials import AzureOpenAICredentials\n",
    "from nbo.schema import (\n",
    "    AppDataScienceSettings,\n",
    "    AppInfraSettings,\n",
    "    LLMModelSpec,\n",
    "    OutcomeDetail,\n",
    "    association_id,\n",
    ")\n",
    "\n",
    "credentials = AzureOpenAICredentials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_ds_settings = AppDataScienceSettings(\n",
    "    page_title=\"Loan Underwriting Email Helper\",\n",
    "    page_subtitle=textwrap.dedent(\"\"\"\\\n",
    "        Combine predictive and generative AI to help triage loan applications.\n",
    "        All you need to do is select an application from the dropdown and hit submit!\"\"\"),\n",
    "    record_identifier={\n",
    "        \"column_name\": \"row_id\",\n",
    "        \"display_name\": \"Loan Applicant\",\n",
    "    },\n",
    "    text_explanation_feature=\"desc\",  # Optional, include when a text variable is present and ngrams feature explanations are desired\n",
    "    no_text_gen_label=None,  # Optional, include in predictions where an email is not desired\n",
    "    default_number_of_explanations=3,\n",
    "    default_temperature=0.5,\n",
    "    target_probability_description=\"the likelihood this loan would default\",  # Preceeded in prompt by \"Feature is increasing/decreasing\"\n",
    "    system_prompt=textwrap.dedent(\"\"\"\\\n",
    "        You are loan underwriting officer named Bob and you work for BankCorp., a regional bank.\n",
    "        Your job is to review loan applications and determine if they should be approved or denied.\n",
    "        You have detailed information about your customer's loan application.\n",
    "        You also have a list of important factors that explain why a customer was approved or denied for a loan.\n",
    "        The goal is to incorporate these factors into an email informing the customer of your decision.\"\"\"),\n",
    "    email_prompt=textwrap.dedent(\"\"\"\\\n",
    "        Draft an email to a loan applicant informing them that their request was {prediction_label}.\n",
    "        The email should be addressed to {selected_record} and contain a subject line and body.\n",
    "        Keep the email tone {tone}. Keep the length {verbosity}. Try not to use many emojis.\n",
    "\n",
    "        Incorporate the following list of factors that influenced:\n",
    "\n",
    "        {rsp}\"\"\"),\n",
    "    outcome_details=[  # Each item should be a target value with it's corresponding label and optional description\n",
    "        OutcomeDetail(\n",
    "            prediction=0,\n",
    "            label=\"Approved\",\n",
    "            description=\"The loan request was approved.\",\n",
    "        ),\n",
    "        OutcomeDetail(\n",
    "            prediction=1,\n",
    "            label=\"Rejected\",\n",
    "            description=\"The loan request was denied.\",\n",
    "        ),\n",
    "    ],\n",
    "    custom_metric_baselines=custom_metric_baselines,\n",
    "    association_id_column_name=association_id,\n",
    "    tones=[\n",
    "        \"authoritative and expert\",\n",
    "        \"educational and informative\",\n",
    "        \"formal and elevated\",\n",
    "        \"friendly and casual\",\n",
    "        \"lighthearted and funny\",\n",
    "        \"witty and playful\",\n",
    "    ],\n",
    "    verbosity=[\"short and sweet\", \"normal\", \"long and detailed\"],\n",
    "    models=[\n",
    "        LLMModelSpec(\n",
    "            name=credentials.azure_deployment,\n",
    "            input_price_per_1k_tokens=0.001,  # update these values based on the model's pricing\n",
    "            output_price_per_1k_tokens=0.002,\n",
    "        ),\n",
    "        # LLMModelSpec(\n",
    "        #     name=\"gpt-35-turbo-16k\",\n",
    "        #     input_price_per_1k_tokens=0.003,\n",
    "        #     output_price_per_1k_tokens=0.004,\n",
    "        # ),\n",
    "        # LLMModelSpec(\n",
    "        #     name=\"gpt-4\",\n",
    "        #     input_price_per_1k_tokens=0.005,\n",
    "        #     output_price_per_1k_tokens=0.015,\n",
    "        # ),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in app_ds_settings.models:\n",
    "    try:\n",
    "        credentials.test(model=model.name)\n",
    "    except Exception as e:\n",
    "        print(f\"Error with model {model.name}: {e}\")\n",
    "        raise ValueError(f\"The azure deployment {model.name} is not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infra.common.schema import (\n",
    "    AdvancedOptionsArgs,\n",
    "    AnalyzeAndModelArgs,\n",
    "    AutopilotRunArgs,\n",
    ")\n",
    "\n",
    "use_case_name = f\"NBO Underwriting [{project_name}]\"\n",
    "use_case_description = \"Loan Underwriting\"\n",
    "\n",
    "dataset_name = f\"NBO Loan Underwriting Training Data [{project_name}]\"\n",
    "file_path = \"assets/underwriting_training.csv\"\n",
    "\n",
    "\n",
    "autopilotrun_args = AutopilotRunArgs(\n",
    "    name=f\"NBO Underwriting AutoPilot Run [{project_name}]\",\n",
    "    analyze_and_model_config=AnalyzeAndModelArgs(\n",
    "        metric=\"LogLoss\",\n",
    "        mode=\"quick\",\n",
    "        target=\"is_bad\",\n",
    "    ),\n",
    "    advanced_options_config=AdvancedOptionsArgs(\n",
    "        seed=42,\n",
    "        shap_only_mode=True,\n",
    "    ),\n",
    ")\n",
    "\n",
    "registered_model_name = f\"NBO [{project_name}]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datarobotx.idp.autopilot import get_or_create_autopilot_run\n",
    "from datarobotx.idp.datasets import get_or_create_dataset_from_file\n",
    "from datarobotx.idp.registered_model_versions import (\n",
    "    get_or_create_registered_leaderboard_model_version,\n",
    ")\n",
    "from datarobotx.idp.use_cases import get_or_create_use_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Creating Use Case {use_case_name}\")\n",
    "\n",
    "if \"DATAROBOT_DEFAULT_USE_CASE\" in os.environ:\n",
    "    use_case_id = os.environ[\"DATAROBOT_DEFAULT_USE_CASE\"]\n",
    "else:\n",
    "    use_case_id = get_or_create_use_case(\n",
    "        endpoint=client.endpoint,\n",
    "        token=client.token,\n",
    "        name=use_case_name,\n",
    "        description=use_case_description,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Creating Dataset {dataset_name}\")\n",
    "dataset_id = get_or_create_dataset_from_file(\n",
    "    token=client.token,\n",
    "    endpoint=client.endpoint,\n",
    "    name=dataset_name,\n",
    "    file_path=file_path,\n",
    "    use_cases=use_case_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Creating Autopilot Run {autopilotrun_args.name}\")\n",
    "project_id = get_or_create_autopilot_run(\n",
    "    token=client.token,\n",
    "    endpoint=client.endpoint,\n",
    "    dataset_id=dataset_id,\n",
    "    use_case=use_case_id,\n",
    "    **autopilotrun_args.model_dump(mode=\"json\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommended_model_id = dr.ModelRecommendation.get(project_id).model_id  # type: ignore[union-attr,attr-defined]\n",
    "\n",
    "try:\n",
    "    model = dr.Model.get(project_id, recommended_model_id)  # type: ignore[attr-defined]\n",
    "    prediction_threshold = model.get_roc_curve(\n",
    "        source=\"validation\"\n",
    "    ).get_best_f1_threshold()\n",
    "except Exception:\n",
    "    prediction_threshold = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(f\"Best model: {model.model_type}\\n\\nMetrics:\")\n",
    "\n",
    "pd.DataFrame.from_records(model.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating Registered Model Version...\")\n",
    "registered_model_version_id = get_or_create_registered_leaderboard_model_version(\n",
    "    token=client.token,\n",
    "    endpoint=client.endpoint,\n",
    "    model_id=recommended_model_id,\n",
    "    registered_model_name=registered_model_name,\n",
    "    prediction_threshold=prediction_threshold,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_infra_settings = AppInfraSettings(\n",
    "    registered_model_name=registered_model_name,\n",
    "    registered_model_version_id=registered_model_version_id,\n",
    "    scoring_dataset_id=dataset_id,\n",
    "    use_case_id=use_case_id,\n",
    "    project_id=project_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "from infra.settings_main import (\n",
    "    model_training_output_ds_settings,\n",
    "    model_training_output_infra_settings,\n",
    ")\n",
    "\n",
    "with open(model_training_output_ds_settings, \"w\") as f:\n",
    "    yaml.safe_dump(app_ds_settings.model_dump(mode=\"json\"), f)\n",
    "with open(model_training_output_infra_settings, \"w\") as f:\n",
    "    yaml.safe_dump(app_infra_settings.model_dump(mode=\"json\"), f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
